# Secure Media Processor - Docker Compose Configuration
# Secure data pipeline for cloud-to-GPU transfers
#
# Usage:
#   CPU:       docker-compose up smp
#   GPU:       docker-compose up smp-gpu
#   Medical:   docker-compose up smp-medical
#   All:       docker-compose up

version: '3.8'

services:
  # ==========================================================================
  # CPU Version (default)
  # ==========================================================================
  smp:
    build:
      context: .
      dockerfile: Dockerfile
    image: secure-media-processor:latest
    container_name: smp
    volumes:
      # Mount directories for data persistence
      - ./data/keys:/app/keys:rw
      - ./data/input:/app/data/input:ro
      - ./data/output:/app/data/output:rw
      - ./data/temp:/app/data/temp:rw
    environment:
      # AWS credentials (optional)
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_BUCKET_NAME=${AWS_BUCKET_NAME:-}
      # GCP credentials (optional)
      - GCP_PROJECT_ID=${GCP_PROJECT_ID:-}
      - GCP_BUCKET_NAME=${GCP_BUCKET_NAME:-}
      # Azure credentials (optional)
      - AZURE_STORAGE_CONNECTION_STRING=${AZURE_STORAGE_CONNECTION_STRING:-}
      - AZURE_STORAGE_ACCOUNT=${AZURE_STORAGE_ACCOUNT:-}
      - AZURE_STORAGE_KEY=${AZURE_STORAGE_KEY:-}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME:-}
      # Dropbox credentials (optional)
      - DROPBOX_ACCESS_TOKEN=${DROPBOX_ACCESS_TOKEN:-}
      # Processing settings
      - GPU_ENABLED=false
      - BATCH_SIZE=${BATCH_SIZE:-32}
      - MAX_WORKERS=${MAX_WORKERS:-4}
    stdin_open: true
    tty: true
    restart: "no"

  # ==========================================================================
  # GPU Version (requires nvidia-container-toolkit)
  # ==========================================================================
  smp-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    image: secure-media-processor:gpu
    container_name: smp-gpu
    volumes:
      - ./data/keys:/app/keys:rw
      - ./data/input:/app/data/input:ro
      - ./data/output:/app/data/output:rw
      - ./data/temp:/app/data/temp:rw
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_BUCKET_NAME=${AWS_BUCKET_NAME:-}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID:-}
      - GCP_BUCKET_NAME=${GCP_BUCKET_NAME:-}
      - AZURE_STORAGE_CONNECTION_STRING=${AZURE_STORAGE_CONNECTION_STRING:-}
      - AZURE_STORAGE_ACCOUNT=${AZURE_STORAGE_ACCOUNT:-}
      - AZURE_STORAGE_KEY=${AZURE_STORAGE_KEY:-}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME:-}
      - DROPBOX_ACCESS_TOKEN=${DROPBOX_ACCESS_TOKEN:-}
      - GPU_ENABLED=true
      - BATCH_SIZE=${BATCH_SIZE:-32}
      - MAX_WORKERS=${MAX_WORKERS:-4}
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true
    tty: true
    restart: "no"

  # ==========================================================================
  # Medical Processing Version (with DICOM support)
  # ==========================================================================
  smp-medical:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    image: secure-media-processor:medical
    container_name: smp-medical
    volumes:
      - ./data/keys:/app/keys:rw
      - ./data/input:/app/data/input:ro
      - ./data/output:/app/data/output:rw
      - ./data/temp:/app/data/temp:rw
      - ./data/studies:/app/data/studies:rw
      - ./data/audit:/app/data/audit:rw
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_BUCKET_NAME=${AWS_BUCKET_NAME:-}
      - AZURE_STORAGE_CONNECTION_STRING=${AZURE_STORAGE_CONNECTION_STRING:-}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME:-}
      - GPU_ENABLED=true
      - BATCH_SIZE=${BATCH_SIZE:-16}
      - MAX_WORKERS=${MAX_WORKERS:-2}
      - NVIDIA_VISIBLE_DEVICES=all
      # HIPAA compliance settings
      - AUDIT_LOG_PATH=/app/data/audit
      - SECURE_DELETE=true
      - ENCRYPTION_ENABLED=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true
    tty: true
    restart: "no"

  # ==========================================================================
  # Development Version (mounts source code for live editing)
  # ==========================================================================
  smp-dev:
    build:
      context: .
      dockerfile: Dockerfile
    image: secure-media-processor:dev
    container_name: smp-dev
    volumes:
      # Mount source for live development
      - ./src:/app/src:ro
      - ./tests:/app/tests:ro
      - ./pyproject.toml:/app/pyproject.toml:ro
      - ./docs:/app/docs:ro
      - ./plugins:/app/plugins:ro
      # Data directories
      - ./data/keys:/app/keys:rw
      - ./data/input:/app/data/input:ro
      - ./data/output:/app/data/output:rw
      - ./data/temp:/app/data/temp:rw
    environment:
      - GPU_ENABLED=false
      - PYTHONDONTWRITEBYTECODE=0
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AZURE_STORAGE_CONNECTION_STRING=${AZURE_STORAGE_CONNECTION_STRING:-}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME:-}
    command: ["--help"]
    stdin_open: true
    tty: true

  # ==========================================================================
  # Test Runner
  # ==========================================================================
  smp-test:
    build:
      context: .
      dockerfile: Dockerfile
    image: secure-media-processor:test
    container_name: smp-test
    volumes:
      - ./src:/app/src:ro
      - ./tests:/app/tests:ro
      - ./pyproject.toml:/app/pyproject.toml:ro
    environment:
      - PYTHONDONTWRITEBYTECODE=0
    entrypoint: ["pytest"]
    command: ["-v", "--tb=short"]

# ==========================================================================
# Volumes for data persistence
# ==========================================================================
volumes:
  keys:
    driver: local
  input:
    driver: local
  output:
    driver: local
  temp:
    driver: local
  studies:
    driver: local
  audit:
    driver: local
